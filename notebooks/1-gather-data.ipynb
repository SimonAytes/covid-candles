{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selectorlib import Extractor\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from dateutil import parser as dateparser\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather product page ASIN numbers from TXT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 106 ASINS\n"
     ]
    }
   ],
   "source": [
    "asins_file = open(\"./data/asins.txt\", \"r\")\n",
    "content = asins_file.read()\n",
    "asins = content.split(\"\\n\")\n",
    "asins_file.close()\n",
    "print(f\"Imported {len(asins)} ASINS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather reviews from product page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Extractor by reading from the YAML file\n",
    "extractor = Extractor.from_yaml_file('./src/selectors.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):    \n",
    "    headers = {\n",
    "        'authority': 'www.amazon.com',\n",
    "        'pragma': 'no-cache',\n",
    "        'cache-control': 'no-cache',\n",
    "        'dnt': '1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.64 Safari/537.36',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'sec-fetch-site': 'none',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    }\n",
    "    \n",
    "    # Download the page\n",
    "    r = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Return the HTML as text \n",
    "    return extractor.extract(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a review URL from the ASIN number\n",
    "def get_page_url(asin, page_no, limit):\n",
    "    # Define the template URL\n",
    "    t_url = f\"https://www.amazon.com/product-reviews/{asin}\"\n",
    "    \n",
    "    # Check if the target page is after page 1\n",
    "    if page_no > 0:\n",
    "        # Check that the target page is within the limit\n",
    "        if page_no <= limit:\n",
    "            t_url = t_url + f\"/?pageNumber={page_no}\"\n",
    "            return t_url\n",
    "    # If these conditions are not met, return the template URL as-is\n",
    "    elif page_no == 0:\n",
    "        return t_url\n",
    "    \n",
    "    # Else return the flag string\n",
    "    return \"FAILS CONDITION CHECK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty data frame with column names\n",
    "reviews = pd.DataFrame(columns = [\"product_title\", \"asin\", \"author\", \"review\", \"rating\", \"date\", \"url\"])\n",
    "\n",
    "# Max. number of pages to scrape (assume 10 reviews per page)\n",
    "limit = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping...\n",
      "Done gathering 10396 reviews in 550 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "tick = dt.datetime.now()\n",
    "\n",
    "# Print start message\n",
    "print(\"Scraping...\")\n",
    "\n",
    "# Scrape urls for reviews and append to data\n",
    "for asin in asins:\n",
    "    # Reset loop variables\n",
    "    page_flag = True\n",
    "    page_no = 0\n",
    "    \n",
    "    # Loop through a product's reviews until the loop variables are flagged\n",
    "    while page_flag:\n",
    "        curr_url = get_page_url(asin, page_no, limit)\n",
    "        \n",
    "        # Check for a valid URL\n",
    "        if \"FAILS CONDITION CHECK\" in curr_url:\n",
    "            page_flag = False\n",
    "            break\n",
    "        \n",
    "        # Gather data from scraper\n",
    "        data = scrape_page(curr_url)\n",
    "        \n",
    "        # Try to parse data, set flag to false otherwise\n",
    "        try:\n",
    "            # Proceed if data was recieved\n",
    "            if data:\n",
    "                for r in data['reviews']:\n",
    "                    # Create a temporary df to store gathered data\n",
    "                    t_df = {\"product_title\":data['product_title'],\n",
    "                            \"asin\":asin,\n",
    "                            \"author\":r['author'], \n",
    "                            \"review\":r['content'], \n",
    "                            \"rating\":float(r['rating'].split(' out of')[0]), \n",
    "                            \"date\":dateparser.parse(r['date'].split('on ')[-1]).strftime('%Y-%m-%d'), \n",
    "                            \"url\":url}\n",
    "\n",
    "                    # Append temporary df to reviews df\n",
    "                    reviews = reviews.append(t_df, ignore_index = True)\n",
    "            # If no data was recieved, flag output\n",
    "            else:\n",
    "                print(f\"Page flag thrown at page {page_no}\")\n",
    "                page_flag = False\n",
    "\n",
    "            # Increment page number\n",
    "            page_no = page_no + 1\n",
    "        # Catch any exceptions and continue to next ASIN no.\n",
    "        except:\n",
    "            page_flag = False\n",
    "\n",
    "# Stop timer            \n",
    "tock = dt.datetime.now() - tick\n",
    "\n",
    "# Print success message with information\n",
    "print(f\"Done gathering {reviews.shape[0]} reviews in {tock.seconds} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>asin</th>\n",
       "      <th>author</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yankee Candle Large Jar Candle Home Sweet Home</td>\n",
       "      <td>B000WUFVR0</td>\n",
       "      <td>David C.</td>\n",
       "      <td>I usually have good experience with Yankee Can...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>https://www.amazon.com/s?k=yankee+candles&amp;crid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_title        asin    author  \\\n",
       "0  Yankee Candle Large Jar Candle Home Sweet Home  B000WUFVR0  David C.   \n",
       "\n",
       "                                              review  rating        date  \\\n",
       "0  I usually have good experience with Yankee Can...     2.0  2019-01-18   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.amazon.com/s?k=yankee+candles&crid...  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output reviews data to the \"raw\" folder\n",
    "reviews.to_csv(\"./data/raw/reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include data within the given data range\n",
    "date_filter = (reviews['date'] >= \"2020-03-01\") & (reviews['date'] <= \"2022-01-16\")\n",
    "reviews = reviews.loc[date_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output filtered reviews data to the \"interim\" folder\n",
    "reviews.to_csv(\"./data/interim/reviews-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the number of reviews on each day and output to CSV\n",
    "reviews_by_day = reviews['date'].value_counts()\n",
    "reviews_by_day = reviews_by_day.to_frame().reset_index()\n",
    "reviews_by_day = reviews_by_day.rename(columns={\"index\":\"date\", \"date\":\"freq\"})\n",
    "reviews_by_day.to_csv(\"./data/interim/reviews_by_day.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and set up COVID-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in COVID-19 Data from JHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all-time COVID-19 data from OWID GitHub\n",
    "covid_data = pd.read_csv('https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output raw data to csv in the \"raw\" folder\n",
    "covid_data.to_csv(\"./data/raw/owid_covid_19_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "covid_data.head(1)\n",
    "# Date in format: YYYYMMDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter COVID-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce columns to only those we need\n",
    "covid_data = covid_data[['date', 'iso_code', 'location', 'total_cases', 'new_cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include data from the USA\n",
    "covid_data = covid_data[covid_data['iso_code'] == \"USA\"]\n",
    "\n",
    "# Filter to only include data within the given data range\n",
    "date_filter = (covid_data['date'] >= \"2020-03-01\") & (covid_data['date'] <= \"2022-01-16\")\n",
    "covid_data = covid_data.loc[date_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>location</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148027</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date iso_code       location  total_cases  new_cases\n",
       "148027  2020-03-01      USA  United States         32.0        7.0"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Data\n",
    "covid_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output COVID-19 data to data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output reviews df as a CSV\n",
    "covid_data.to_csv(\"./data/interim/covid_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
