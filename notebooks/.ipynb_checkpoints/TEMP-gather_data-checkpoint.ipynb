{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selectorlib import Extractor\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from dateutil import parser as dateparser\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather product page ASIN numbers from TXT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 106 ASINS\n"
     ]
    }
   ],
   "source": [
    "asins_file = open(\"./data/asins.txt\", \"r\")\n",
    "content = asins_file.read()\n",
    "asins = content.split(\"\\n\")\n",
    "asins_file.close()\n",
    "print(f\"Imported {len(asins)} ASINS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather reviews from product page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Extractor by reading from the YAML file\n",
    "extractor = Extractor.from_yaml_file('./src/selectors.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):    \n",
    "    headers = {\n",
    "        'authority': 'www.amazon.com',\n",
    "        'pragma': 'no-cache',\n",
    "        'cache-control': 'no-cache',\n",
    "        'dnt': '1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.64 Safari/537.36',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'sec-fetch-site': 'none',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    }\n",
    "\n",
    "    # Download the page using requests\n",
    "    #print(f\"Downloading {url}\")\n",
    "    r = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Pass the HTML of the page and create \n",
    "    return extractor.extract(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_url(asin, page_no, limit):\n",
    "    t_url = f\"https://www.amazon.com/product-reviews/{asin}\"\n",
    "    \n",
    "    if page_no > 0:\n",
    "        if page_no <= limit:\n",
    "            t_url = t_url + f\"/?pageNumber={page_no}\"\n",
    "            return t_url\n",
    "    elif page_no == 0:\n",
    "        return t_url\n",
    "        \n",
    "    return \"FAILS CONDITION CHECK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the data frame\n",
    "reviews = pd.DataFrame(columns = [\"product_title\", \"asin\", \"author\", \"review\", \"rating\", \"date\", \"url\"])\n",
    "\n",
    "# Max. number of pages to scrape (assume 10 reviews per page)\n",
    "limit = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered B000WUFVR0\n",
      "Gathered B001D6HB0M\n",
      "Gathered B000W3V8S8\n",
      "Gathered B007FSDIJA\n",
      "Gathered B01MTS599T\n",
      "Gathered B000X457HO\n",
      "Gathered B000ORX6WI\n",
      "Gathered B000JDGC78\n",
      "Gathered B0032JHSP6\n",
      "Gathered B078VJPW4Z\n",
      "Gathered B07WDYMGZN\n",
      "Gathered B004USM1A0\n",
      "Gathered B000C2TB6U\n",
      "Gathered B004G9DV66\n",
      "Gathered B0057I5TIS\n",
      "Gathered B001PAPPKY\n",
      "Gathered B004G9C0SQ\n",
      "Gathered B002UE6YQ8\n",
      "Gathered B001U40C6W\n",
      "Gathered B000P6THK8\n",
      "Gathered B07PD1GJDN\n",
      "Gathered B00J6CH1VO\n",
      "Gathered B08TZT1N2C\n",
      "Gathered B08TZ7VTNX\n",
      "Gathered B07D37WXHH\n",
      "Gathered B00069ZDJS\n",
      "Gathered B07F82KQPZ\n",
      "Gathered B07T94X7GB\n",
      "Gathered B08TZRRBMZ\n",
      "Gathered B07D39RV2K\n",
      "Gathered B08TZS82PY\n",
      "Gathered B0044R5L6S\n",
      "Gathered B07D396V8Y\n",
      "Gathered B07D39HSRQ\n",
      "Gathered B00O60M2D8\n",
      "Gathered B01NAAQLZ1\n",
      "Gathered B06X6H95GW\n",
      "Gathered B000WQZ5PC\n",
      "Gathered B005OMNPII\n",
      "Gathered B07P9S8VZR\n",
      "Gathered B001U3WTP0\n",
      "Gathered B0099X1DFU\n",
      "Gathered B07D3B3Q84\n",
      "Gathered B00O60L28E\n",
      "Gathered B000TVJ6XW\n",
      "Gathered B07D37ZFBH\n",
      "Gathered B0044R1W98\n",
      "Gathered B000CB4UQM\n",
      "Gathered B07ZQQVC9S\n",
      "Gathered B019PN2DX4\n",
      "Gathered B07GV8JBZN\n",
      "Gathered B004UAI0B2\n",
      "Gathered B07QK1W5BB\n",
      "Gathered B0842JP2R5\n",
      "Gathered B082MQNWP5\n",
      "Gathered B081ZHJKRR\n",
      "Gathered B0842JFKK6\n",
      "Gathered B076PVV9YH\n",
      "Gathered B084CVW6JR\n",
      "Gathered B00JJXLDGE\n",
      "Gathered B07QYB6R2Q\n",
      "Gathered B003U2J4XY\n",
      "Gathered B083Z1ZZ6Y\n",
      "Gathered B0155OG8LK\n",
      "Gathered B07YZN4X7V\n",
      "Gathered B07PD7ZSY9\n",
      "Gathered B0155OGEUU\n",
      "Gathered B0842JLJGH\n",
      "Gathered B08PMPNSS4\n",
      "Gathered B07SLT3C47\n",
      "Gathered B07D3B3Q85\n",
      "Gathered B0842JQD7B\n",
      "Gathered B0842JHF9N\n",
      "Gathered B07PD84GR2\n",
      "Gathered B07QGPQ5FG\n",
      "Gathered B07QGQ3R73\n",
      "Gathered B0842JMGYP\n",
      "Gathered B082X6RTSB\n",
      "Gathered B01AL6DN1A\n",
      "Gathered B08SR4PJN8\n",
      "Gathered B07PD7ZSY7\n",
      "Gathered B08SQZB27R\n",
      "Gathered B07D4HH32G\n",
      "Gathered B0842JN4R4\n",
      "Gathered B09C4469BH\n",
      "Gathered B07Q78FNMK\n",
      "Gathered B01GIDWCPS\n",
      "Gathered B07T6CZYPG\n",
      "Gathered B0995CPL62\n",
      "Gathered B000W3T9GG\n",
      "Gathered B071KV69D3\n",
      "Gathered B06VVL5YBT\n",
      "Gathered B07P9S8RJT\n",
      "Gathered B07PJ1NF4J\n",
      "Gathered B07D4HFPZQ\n",
      "Gathered B083YSKXP5\n",
      "Gathered B0842JFM6P\n",
      "Gathered B08PN6LM47\n",
      "Gathered B01N8WUHDI\n",
      "Gathered B00O4O16GA\n",
      "Gathered B01BKS87LY\n",
      "Gathered B07WZGY3LM\n",
      "Gathered B000RY54LO\n",
      "Gathered B01N8SP1J3\n",
      "Gathered B07D391NSS\n",
      "Gathered B07TC7X461\n",
      "Done gathering 7659 reviews in 394 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "tick = dt.datetime.now()\n",
    "\n",
    "print(\"Scraping...\")\n",
    "\n",
    "# Scrape urls for reviews and append to datad\n",
    "for asin in asins:\n",
    "    # Reset loop variables\n",
    "    page_flag = True\n",
    "    page_no = 0\n",
    "\n",
    "    while page_flag:\n",
    "        curr_url = get_page_url(asin, page_no, limit)\n",
    "        \n",
    "        # Check for a valid URL\n",
    "        if \"FAILS CONDITION CHECK\" in curr_url:\n",
    "            page_flag = False\n",
    "            break\n",
    "        \n",
    "        # Gather data from scraper\n",
    "        data = scrape_page(curr_url)\n",
    "        \n",
    "        # Try to parse data, set flag to false otherwise\n",
    "        try:\n",
    "            if data:\n",
    "                for r in data['reviews']:\n",
    "                    t_df = {\"product_title\":data['product_title'],\n",
    "                            \"asin\":asin,\n",
    "                            \"author\":r['author'], \n",
    "                            \"review\":r['content'], \n",
    "                            \"rating\":float(r['rating'].split(' out of')[0]), \n",
    "                            \"date\":dateparser.parse(r['date'].split('on ')[-1]).strftime('%B %d, %Y'), \n",
    "                            \"url\":url}\n",
    "\n",
    "                    # Add review data to data frame\n",
    "                    reviews = reviews.append(t_df, ignore_index = True)\n",
    "            else:\n",
    "                print(f\"Page flag thrown at page {page_no}\")\n",
    "                page_flag = False\n",
    "\n",
    "            # Increment page number\n",
    "            page_no = page_no + 1\n",
    "        except:\n",
    "            page_flag = False\n",
    "    \n",
    "    #print(f\"Gathered {asin}\")\n",
    "\n",
    "# Stop timer            \n",
    "tock = dt.datetime.now() - tick\n",
    "\n",
    "# Print success message\n",
    "print(f\"Done gathering {reviews.shape[0]} reviews in {tock.seconds} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output reviews data to the \"raw\" folder\n",
    "reviews.to_csv(\"./data/raw/reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_by_day = reviews['date'].value_counts()\n",
    "reviews_by_day = reviews_by_day.to_frame().reset_index()\n",
    "reviews_by_day = reviews_by_day.rename(columns={\"index\":\"date\", \"date\":\"freq\"})\n",
    "reviews_by_day.to_csv(\"./data/raw/reviews_by_day.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and set up COVID-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in COVID-19 Data from JHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all-time COVID-19 data from OWID GitHub\n",
    "covid_data = pd.read_csv('https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output raw data to csv in the \"raw\" folder\n",
    "covid_data.to_csv(\"./data/raw/owid_covid_19_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview data\n",
    "covid_data.head(1)\n",
    "# Date in format: YYYYMMDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter COVID-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce columns to only those we need\n",
    "covid_data = covid_data[['date', 'iso_code', 'location', 'total_cases', 'new_cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include data from the USA\n",
    "covid_data = covid_data[covid_data['iso_code'] == \"USA\"]\n",
    "\n",
    "# Filter to only include data within the given data range\n",
    "date_filter = (covid_data['date'] >= \"2020-03-01\") & (covid_data['date'] <= \"2022-01-20\")\n",
    "covid_data = covid_data.loc[date_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>location</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148027</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date iso_code       location  total_cases  new_cases\n",
       "148027  2020-03-01      USA  United States         32.0        7.0"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Data\n",
    "covid_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output COVID-19 data to data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output reviews df as a CSV\n",
    "covid_data.to_csv(\"./data/interim/covid_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
